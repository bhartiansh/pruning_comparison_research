# pruning_comparison_research

gpt prompt
Iâ€™m working on a CNN pruning comparison project using the CIFAR-10 dataset. I have a custom ResNet-56 model implemented in Keras and Iâ€™m comparing five pruning techniques on it. I want to train each pruned model from scratch and compare their performance with the baseline. I also have limited Colab units, so I need optimized code.

Hereâ€™s what I have done so far and need:

âœ… Dataset:
	â€¢	CIFAR-10 (already normalized and preprocessed)

âœ… Baseline:
	â€¢	ResNet-56 from scratch (custom 6n+2 Keras model)

âœ… Goal:
	â€¢	Train the baseline and 5 pruned variants of it on CIFAR-10
	â€¢	Compare accuracy, training time, parameter sparsity, etc.

ðŸ§ª Pruning Methods:
	1.	Magnitude-Based Pruning (Global Unstructured) â€“ DONE âœ…
	2.	SNIP (Single-shot pruning using saliency scores)
	3.	Lottery Ticket Hypothesis (LTH)
	4.	L1-Norm Filter Pruning (Structured Pruning)
	5.	Random Pruning (as control baseline)

ðŸ”§ Requirements:
	â€¢	Efficient training setup (early stopping, checkpoints)
	â€¢	Save model weights, training logs, and evaluation metrics
	â€¢	Code should be Colab- and RTX 4060â€“friendly
	â€¢	Show side-by-side comparison plots (accuracy, loss, params)

Start from method 2 (SNIP) if resuming progress.
